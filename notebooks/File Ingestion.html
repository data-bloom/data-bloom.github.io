<meta charset="utf-8" />
    <title>File Ingestion</title>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="css/style.css" rel="stylesheet" type="text/css">
    <link rel="shortcut icon" href="bloom.ico" type="image/x-icon">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <style type="text/css">
        {
            {
                css
            }
        }
    </style>
    <style type="text/css">
        {
            {
                css
            }
        }
    </style>
    <style type="text/css">
        {
            {
                css
            }
        }
    </style>
    

    <!-- Can put analytics code here, if desired -->

    <style type="text/css">
        /* Overrides of notebook CSS for static HTML export */
        
        body {
            overflow: visible;
            padding: 8px;
        }
        
        div#notebook {
            overflow: visible;
            border-top: none;
        }
        
        @media print {
            div.cell {
                display: block;
                page-break-inside: avoid;
            }
            div.output_wrapper {
                display: block;
                page-break-inside: avoid;
            }
            div.output {
                display: block;
                page-break-inside: avoid;
            }
        }
    </style>

    <link rel="stylesheet" href="ipynb.css">

    <!-- Loading mathjax macro -->
    <!-- Load mathjax -->
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration -->
    <!-- Navigation -->
    <div class="container row">
        <a class="pull-right navbar-brand" href="http://data-bloom.com">Data Bloom</a>
    </div>
    <div tabindex="-1" id="notebook" class="border-box-sizing">
        <div class="container" id="notebook-container">
            
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Big-Data-Ingestion">Big Data Ingestion<a class="anchor-link" href="#Big-Data-Ingestion">&#182;</a></h1><h2 id="Business-Problem">Business Problem<a class="anchor-link" href="#Business-Problem">&#182;</a></h2><p>Every business now has more data than can be handled by spreadsheets and traditional databases. So chief data officers for all digital enterprises are creating bigger data lakes at scale on Hadoop. The problem however is that the data lake journey is fraught with governance challenges down the line if not shored up by clear metadata management and governance standards from the start. It turns out that directly opening the data lake for everyone to bring their data, per the intended purpose, is a guaranteed way for the lake to turn into a swamp quickly. There are numerous ways to bring data into Hadoop. Opening and supporting all the available protocols is a governance nightmare.</p>
<p>Instead, we found that the best way to ensure a sustainable metadata governance standard is to design a single data manifold -- a self-service data ingestion WYSIWYG interface -- that quarantines input data and enforces a strict annotation, quality, and ownership standard for raw data. A single manifold also addresses challenges like --</p>
<ol>
<li>schema-integrity challenges of continuous data</li>
<li>overriding and flagging duplicity of data</li>
<li>quarantining unclassified data</li>
<li>inferring structural semantics of unstructured data</li>
<li>profiling and quality-proofing structured data</li>
<li>triggering automatic curation workflows</li>
<li>more...</li>
</ol>
<p>There is a myriad of ways to ingest, infer, characterize, and store raw data into the data lake environment. Below, a few examples of bringing data into the lake from local files (Excel, CSV, JSON, XML), enterprise databases (SQL Server, MySQL, Postgres, Oracle, SAP BW, Teradata), cloud platforms (Google Big Query, Salesforce, Amazon S3), and from the Internet. Although we do not show the drag-n-drop user-interface, the constructs underlying the data bridge are simple and enabled easily by Spark.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Ingesting-Local-File">Ingesting Local File<a class="anchor-link" href="#Ingesting-Local-File">&#182;</a></h2><p>You can use a myriad of inbuilt ways to ingest local data files. If the file is native to big data platform (like avro or json), you may use Spark's data connector framework directly. If the files are binary files like Excel, you may use Pandas and convert files into Spark dataframes (and consequently the Hive warehouse).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># Reading a Excel file</span>
<span class="n">finance_details</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span>
    <span class="s1">&#39;http://go.microsoft.com/fwlink/?LinkID=521962&#39;</span><span class="p">)</span>

<span class="c1"># Display a preview of the file</span>
<span class="n">pd_display</span><span class="p">(</span>
    <span class="n">finance_details</span><span class="p">,</span>
    <span class="sd">&#39;&#39;&#39;Preview of the Excel file from http://go.microsoft.com/fwlink/?LinkID=521962&#39;&#39;&#39;</span>
<span class="p">)</span>

<span class="c1"># Describe the dataset (data columns and their percentile stats) </span>
<span class="n">pd_display</span><span class="p">(</span><span class="n">finance_details</span><span class="o">.</span><span class="n">describe</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">),</span> <span class="s1">&#39;&#39;&#39;Data characteristics&#39;&#39;&#39;</span><span class="p">)</span>

<span class="c1"># Infer the dataset schema (data columns, types) </span>
<span class="n">pd_display</span><span class="p">(</span>
    <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
        <span class="nb">zip</span><span class="p">(</span><span class="n">finance_details</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
            <span class="n">finance_details</span><span class="o">.</span><span class="n">convert_objects</span><span class="p">()</span><span class="o">.</span><span class="n">dtypes</span><span class="o">.</span><span class="n">values</span><span class="p">)),</span>
    <span class="sd">&#39;&#39;&#39;Data types&#39;&#39;&#39;</span><span class="p">)</span>

<span class="c1"># Create a Spark (aka &quot;big data&quot;) frame out of it</span>
<span class="n">finance_df</span> <span class="o">=</span> <span class="n">sqlCtx</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">finance_details</span><span class="p">)</span>

<span class="c1"># Display a preview of the big dataset</span>
<span class="n">pd_display</span><span class="p">(</span>
    <span class="n">finance_df</span><span class="o">.</span><span class="n">limit</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">toPandas</span><span class="p">(),</span>
    <span class="sd">&#39;&#39;&#39;Preview of the Excel file in Spark&#39;s memory&#39;&#39;&#39;</span><span class="p">)</span>

<span class="c1"># Save the Spark dataframe into the data lake; overwriting data if it already exists</span>
<span class="c1"># Make the column names safe for Hadoop standards</span>
<span class="n">finance_df</span><span class="o">.</span><span class="n">select</span><span class="p">([</span>
    <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s1">&#39;{0}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">col</span><span class="p">))</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span>
        <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;[^0-9a-zA-Z_]&#39;</span><span class="p">,</span> <span class="s1">&#39;_&#39;</span><span class="p">,</span> <span class="n">col</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">finance_df</span><span class="o">.</span><span class="n">columns</span>
<span class="p">])</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span>
    <span class="s1">&#39;finance_accts.parquet&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;overwrite&#39;</span><span class="p">)</span>

<span class="c1"># Verify data on disk is intact</span>
<span class="n">pd_display</span><span class="p">(</span>
    <span class="n">sqlCtx</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="s1">&#39;finance_accts.parquet&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">limit</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">toPandas</span><span class="p">(),</span>
    <span class="sd">&#39;&#39;&#39;Preview of the dataframe in data lake disk&#39;&#39;&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Ingesting-HTML-File">Ingesting HTML File<a class="anchor-link" href="#Ingesting-HTML-File">&#182;</a></h2><p>HTML and Network files can be implemented on top of traditional JSCH like API layers. Below, we show examples of ingesting a HTML resource from the web, a SFTP resource from a file server, and file from Windows share.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># Read a HTML resource. In this case, example of most populous countries in the world from Wikipedia</span>
<span class="c1"># First table from https://en.wikipedia.org/wiki/List_of_countries_by_population_(United_Nations)</span>
<span class="n">pd_display</span><span class="p">(</span>
    <span class="n">pd</span><span class="o">.</span><span class="n">read_html</span><span class="p">(</span>
        <span class="s1">&#39;https://en.wikipedia.org/wiki/List_of_countries_by_population_(United_Nations)&#39;</span><span class="p">,</span>
        <span class="n">header</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span>
    <span class="s1">&#39;Most populous countries in the world from HTML page&#39;</span><span class="p">)</span>


<span class="c1"># Write a simple routine to read data file from home directory</span>
<span class="c1"># We are doing this so as to not inline username/password info here in the public notebook</span>
<span class="k">def</span> <span class="nf">read_string</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>


<span class="c1"># Read a file from FTP server</span>
<span class="kn">from</span> <span class="nn">os.path</span> <span class="kn">import</span> <span class="n">expanduser</span>
<span class="c1"># Get home directory</span>
<span class="n">home</span> <span class="o">=</span> <span class="n">expanduser</span><span class="p">(</span><span class="s2">&quot;~/&quot;</span><span class="p">)</span>

<span class="c1"># Import pysftp and copy the SFTP file locally. You may be able to get a file handle too</span>
<span class="c1"># for big files or use spark-sftp connector</span>
<span class="kn">import</span> <span class="nn">pysftp</span>

<span class="c1"># Open a disposable connection</span>
<span class="k">with</span> <span class="n">pysftp</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span>
        <span class="s1">&#39;192.168.1.50&#39;</span><span class="p">,</span>
        <span class="n">username</span><span class="o">=</span><span class="n">read_string</span><span class="p">(</span><span class="s1">&#39;{0}/.uname.txt&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">home</span><span class="p">)),</span>
        <span class="n">password</span><span class="o">=</span><span class="n">read_string</span><span class="p">(</span><span class="s1">&#39;{0}/.pwd.txt&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">home</span><span class="p">)))</span> <span class="k">as</span> <span class="n">sftp</span><span class="p">:</span>
    <span class="k">with</span> <span class="n">sftp</span><span class="o">.</span><span class="n">cd</span><span class="p">(</span><span class="s1">&#39;/tmp&#39;</span><span class="p">):</span>  <span class="c1"># copy locally</span>
        <span class="n">sftp</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;iris.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;iris.csv&#39;</span><span class="p">)</span>

<span class="c1"># Make a dataframe and display</span>
<span class="n">pd_display</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;iris.csv&#39;</span><span class="p">),</span> <span class="s2">&quot;Iris spark dataset from a SFTP file&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Ingesting-from-Cloud">Ingesting from Cloud<a class="anchor-link" href="#Ingesting-from-Cloud">&#182;</a></h2><p>Enterprises are increasingly moving to cloud first where data classification may be more open. ARIBA, Workday, Salesforce, AWS have become increasingly common. Your data first arrives into the cloud. In order to import these datasets into the data lake, you have a decent choice of connectors available currently.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># We will demonstrate use of Salesforce datasets to be brought into the data lake</span>
<span class="n">sfdc_username</span> <span class="o">=</span> <span class="n">read_string</span><span class="p">(</span><span class="s1">&#39;{0}/.sfdcusername.txt&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">home</span><span class="p">))</span>
<span class="n">sfdc_password</span> <span class="o">=</span> <span class="n">read_string</span><span class="p">(</span><span class="s1">&#39;{0}/.sfdcpassword_token.txt&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">home</span><span class="p">))</span>

<span class="c1"># Read the dataset</span>
<span class="n">sfdc_accounts</span> <span class="o">=</span> <span class="n">sqlCtx</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;com.springml.spark.salesforce&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span>
    <span class="s1">&#39;username&#39;</span><span class="p">,</span> <span class="n">sfdc_username</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s1">&#39;password&#39;</span><span class="p">,</span> <span class="n">sfdc_password</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span>
        <span class="s1">&#39;soql&#39;</span><span class="p">,</span> <span class="s1">&#39;SELECT Id, Name, BillingCity FROM Account&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span>
            <span class="s1">&#39;version&#39;</span><span class="p">,</span> <span class="s1">&#39;35.0&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>

<span class="c1"># Show the preview</span>
<span class="n">pd_display</span><span class="p">(</span><span class="n">sfdc_accounts</span><span class="o">.</span><span class="n">toPandas</span><span class="p">(),</span>
           <span class="s2">&quot;Salesforce accounts read into the big data lake&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Ingesting-from-enterprise-databases">Ingesting from enterprise databases<a class="anchor-link" href="#Ingesting-from-enterprise-databases">&#182;</a></h2><p>Enterprises also presumably have existing databases (SQL Server, Oracle), warehouses (Teradata, Netezza), and datamarts (Cognos, Microstrategy). There is existing knowledge in these databases that needs to be transferred into the single data lake as well (logically, if not physically) in order for end to end analytical insights. Most of these data sources (including nosql databases) provide standard JDBC connectivity for Spark.</p>
<p>Underneath, we show an example of ingesting from a simple sqlite database which scales just as easily for bigger MPP warehouses as well like Teradata and SAP.</p>
<p>The JDBC path opens a world of possibilities. <strong>Btw, the Spark dataframes and consequently any big data frames can also be written back to JDBC sources making interoperability with existing databases a breeze!</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># Make a JDBC connection from the local SQLite database into a Spark dataframe</span>
<span class="n">jdbc_db</span> <span class="o">=</span> <span class="n">sqlCtx</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">jdbc</span><span class="p">(</span>
    <span class="n">url</span><span class="o">=</span><span class="s2">r&quot;jdbc:sqlite:{0}/chinook.db&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(</span>
    <span class="p">)),</span>  <span class="c1"># The source of the file</span>
    <span class="n">table</span><span class="o">=</span><span class="s2">&quot;(select * from customers) a&quot;</span><span class="p">,</span>  <span class="c1"># Prune dataset that you load</span>
    <span class="n">properties</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;driver&#39;</span><span class="p">:</span>
                <span class="s1">&#39;org.sqlite.JDBC&#39;</span><span class="p">})</span>  <span class="c1"># Driver in the classpath if needed</span>

<span class="c1"># Display a preview.</span>
<span class="n">pd_display</span><span class="p">(</span><span class="n">jdbc_db</span><span class="o">.</span><span class="n">toPandas</span><span class="p">(</span>
<span class="p">),</span> <span class="s1">&#39;Any JDBC source can be materialized in memory and constructed as a Spark dataframe&#39;</span>
           <span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Analytics-in-memory">Analytics in memory<a class="anchor-link" href="#Analytics-in-memory">&#182;</a></h1><p>So what can we do with the data in the lake? Whether that data is physically copied in the warehouse, saved to a local columnar file, or logically referenced in-memory from an existing remote source, most analytics can directly be applied in place. This makes ephemeral analytics and pipelined ETL at scale easy to implement in Spark.</p>
<p>Underneath, we just pick the simplest Iris flower dataset and visually explore for the separability of the features.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># Wrap the iris dataset big data frame</span>
<span class="n">iris_pandas_dataset</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;iris.csv&#39;</span><span class="p">)</span>

<span class="c1"># Just to show a complex data file...</span>
<span class="c1"># Save the Pandas object as a JSON file</span>
<span class="n">iris_pandas_dataset</span><span class="o">.</span><span class="n">to_json</span><span class="p">(</span><span class="s1">&#39;iris.json&#39;</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="s1">&#39;records&#39;</span><span class="p">)</span>

<span class="c1"># Just for demonstration, read the JSON file too</span>
<span class="n">iris_dataset</span> <span class="o">=</span> <span class="n">sqlCtx</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">json</span><span class="p">(</span><span class="s1">&#39;iris.json&#39;</span><span class="p">)</span>

<span class="c1"># Show a preview of the data</span>
<span class="n">pd_display</span><span class="p">(</span><span class="n">iris_dataset</span><span class="o">.</span><span class="n">toPandas</span><span class="p">(),</span> <span class="s2">&quot;Preview of the raw Iris dataset&quot;</span><span class="p">)</span>

<span class="c1"># Describe the dataset</span>
<span class="n">pd_display</span><span class="p">(</span>
    <span class="n">iris_dataset</span><span class="o">.</span><span class="n">describe</span><span class="p">(</span>
        <span class="p">[</span><span class="s1">&#39;`{0}`&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">colname</span><span class="p">)</span>
         <span class="k">for</span> <span class="n">colname</span> <span class="ow">in</span> <span class="n">iris_dataset</span><span class="o">.</span><span class="n">columns</span><span class="p">])</span><span class="o">.</span><span class="n">toPandas</span><span class="p">()</span><span class="o">.</span><span class="n">T</span><span class="p">,</span>
    <span class="s1">&#39;Column statistics of the dataset&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Data-Visualization">Data Visualization<a class="anchor-link" href="#Data-Visualization">&#182;</a></h2><p>In order to check the separability of the flowers, let us visually rendition the scatter plot of the data. If they are separable, we ought to easily spot the void space between the scatter groups.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline

<span class="c1"># Plot the dataset; color each species of Iris with different colors</span>
<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">iris_dataset</span><span class="o">.</span><span class="n">toPandas</span><span class="p">(),</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;species&quot;</span><span class="p">);</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Findings">Findings<a class="anchor-link" href="#Findings">&#182;</a></h2><p>We observe that Setosa species is of course clearly separable from the other two species. The Versicolor and Virginica species of Iris are however not easily separable.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Data-Shaping">Data Shaping<a class="anchor-link" href="#Data-Shaping">&#182;</a></h1><p>Raw files do not come prepped for analysis. You must indispensably change the raw data into an analytical shape first. You can choose to do that in the lake before downstream data marts can consume the data or directly atop the ODBC connector on top of Impala/Tez/Spark. Underneath, we show how you can implement star-schema in Spark.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote><h3 id="Men-are-from-Mars.-Women-are-from-Venus.">Men are from Mars. Women are from Venus.<a class="anchor-link" href="#Men-are-from-Mars.-Women-are-from-Venus.">&#182;</a></h3>
</blockquote>
<h2 id="Gender-Movies">Gender Movies<a class="anchor-link" href="#Gender-Movies">&#182;</a></h2><p>The movie lens data (<a href="http://grouplens.org/datasets/movielens/">http://grouplens.org/datasets/movielens/</a>) provides Likert ratings of movies as entered by viewers. Based on this data, we want to identify if there are movies that have substantive difference in likings by men and women; and if there are, we want to identify the top 10 movies that have maximum disagreement between men and women.</p>
<p>Underneath is also an example for how can mix imperative, declarative, and functional style programming to shape the data.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># Bring the ratings, users, and movies data from the web</span>

<span class="c1"># Ratings</span>
<span class="n">ratings</span> <span class="o">=</span> <span class="n">sqlCtx</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span>
    <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
        <span class="s1">&#39;http://files.grouplens.org/datasets/movielens/ml-100k/u.data&#39;</span><span class="p">,</span>
        <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span>
        <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;user_id&#39;</span><span class="p">,</span> <span class="s1">&#39;item_id&#39;</span><span class="p">,</span> <span class="s1">&#39;rating&#39;</span><span class="p">,</span> <span class="s1">&#39;timestamp&#39;</span><span class="p">],</span>
        <span class="n">usecols</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]))</span>

<span class="c1"># Users</span>
<span class="n">users</span> <span class="o">=</span> <span class="n">sqlCtx</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span>
    <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
        <span class="s1">&#39;http://files.grouplens.org/datasets/movielens/ml-100k/u.user&#39;</span><span class="p">,</span>
        <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;|&#39;</span><span class="p">,</span>
        <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;user_id_dim&#39;</span><span class="p">,</span> <span class="s1">&#39;age&#39;</span><span class="p">,</span> <span class="s1">&#39;gender&#39;</span><span class="p">,</span> <span class="s1">&#39;occupation&#39;</span><span class="p">,</span> <span class="s1">&#39;zip&#39;</span><span class="p">],</span>
        <span class="n">usecols</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]))</span>

<span class="c1"># Movies</span>
<span class="n">movies</span> <span class="o">=</span> <span class="n">sqlCtx</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span>
    <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
        <span class="s1">&#39;http://files.grouplens.org/datasets/movielens/ml-100k/u.item&#39;</span><span class="p">,</span>
        <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;|&quot;</span><span class="p">,</span>
        <span class="n">usecols</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span>
    <span class="n">schema</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;movie_id_dim&#39;</span><span class="p">,</span> <span class="s1">&#39;movie_title&#39;</span><span class="p">])</span>

<span class="c1"># Display the raw dimensional tables of users and movies</span>
<span class="n">pd_display</span><span class="p">(</span><span class="n">movies</span><span class="o">.</span><span class="n">toPandas</span><span class="p">(),</span> <span class="s1">&#39;Movies dimension table from MovieLens&#39;</span><span class="p">)</span>
<span class="n">pd_display</span><span class="p">(</span><span class="n">users</span><span class="o">.</span><span class="n">toPandas</span><span class="p">(),</span> <span class="s1">&#39;Users dimension table from MovieLens&#39;</span><span class="p">)</span>

<span class="c1"># Display the factual ratings table</span>
<span class="n">pd_display</span><span class="p">(</span><span class="n">ratings</span><span class="o">.</span><span class="n">toPandas</span><span class="p">(),</span> <span class="s1">&#39;Ratings fact table from MovieLens&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Star-schema-Join-(Declarative-SQL)">Star-schema Join (Declarative SQL)<a class="anchor-link" href="#Star-schema-Join-(Declarative-SQL)">&#182;</a></h2><p>We can overlay the dimensional tables over factual data with simple multiway join. Let us just employ simple <strong>declarative (SQL)</strong> syntax in Spark to accomplish it. The strongest advantage of using Spark, besides inbuilt machine learning libraries, is the ability to mix and match imperative, declarative, and functional style programming in the same workflow in memory.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># Join the dimensional definitions with factual tables to obtain denormalized representation</span>
<span class="n">norm_ratings</span> <span class="o">=</span> <span class="n">sqlCtx</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span>
    <span class="s1">&#39;select a.*, b.*, c.* from {0} a join {1} b join {2} c on a.user_id = b.user_id_dim and a.item_id = movie_id_dim&#39;</span><span class="o">.</span>
    <span class="n">format</span><span class="p">(</span><span class="n">ratings</span><span class="o">.</span><span class="n">reg</span><span class="p">(),</span> <span class="n">users</span><span class="o">.</span><span class="n">reg</span><span class="p">(),</span> <span class="n">movies</span><span class="o">.</span><span class="n">reg</span><span class="p">()))</span>

<span class="c1"># Show a preview of the star-schema table</span>
<span class="n">pd_display</span><span class="p">(</span>
    <span class="n">norm_ratings</span><span class="o">.</span><span class="n">limit</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">toPandas</span><span class="p">(),</span>
    <span class="s2">&quot;Denormalized star schema movielens ratings table&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Aggregations-(Functional-Programming)">Aggregations (Functional Programming)<a class="anchor-link" href="#Aggregations-(Functional-Programming)">&#182;</a></h2><p>We will employ aggregations using functional programming <strong>(groupBy, agg)</strong> to compute average ratings for every movie as rated by each gender.</p>
<p>The grouping still only groups ratings by gender and leaves ratings on successive rows of data. In order to employ simple delta logic, it is best to place the ratings for each movie per gender in the same row in two different columns. In order to get the columns, we can pivot the grouped table.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># Let us average the rating per movie per gender</span>
<span class="c1"># Group by movie name and gender; compute average rating per group</span>
<span class="n">avg_ratings</span> <span class="o">=</span> <span class="n">norm_ratings</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span>
    <span class="p">[</span><span class="s1">&#39;movie_title&#39;</span><span class="p">,</span> <span class="s1">&#39;gender&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">avg</span><span class="p">(</span><span class="s1">&#39;rating&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s1">&#39;rating&#39;</span><span class="p">))</span>

<span class="c1"># Display the aggregated average ratings</span>
<span class="n">pd_display</span><span class="p">(</span><span class="n">avg_ratings</span><span class="o">.</span><span class="n">toPandas</span><span class="p">(),</span> <span class="s2">&quot;Average ratings by each gender per movie&quot;</span><span class="p">)</span>

<span class="c1"># Pivot to flatten gender averages per movie on a single line</span>
<span class="c1"># Group movie into a single line, but project individual gender ratings</span>
<span class="c1"># as separate columns in the result file.</span>
<span class="n">pivot_avg_ratings</span> <span class="o">=</span> <span class="n">avg_ratings</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s1">&#39;movie_title&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">pivot</span><span class="p">(</span><span class="s1">&#39;gender&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span>
    <span class="n">F</span><span class="o">.</span><span class="n">first</span><span class="p">(</span><span class="s1">&#39;rating&#39;</span><span class="p">))</span>

<span class="c1"># Display the pivoted values to show averages</span>
<span class="n">pd_display</span><span class="p">(</span><span class="n">pivot_avg_ratings</span><span class="o">.</span><span class="n">toPandas</span><span class="p">(),</span>
           <span class="s2">&quot;Average ratings per movie, separated by gender ratings in columns&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Computations-(Declarative-SQL)">Computations (Declarative SQL)<a class="anchor-link" href="#Computations-(Declarative-SQL)">&#182;</a></h2><p>With ratings aligned in the right shape, we can compute movies that have maximum separation of ratings between men and women. Positive diff ratings mean Men like the movies more than women. A negative diff rating means women like the movies better than men.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># Compute movies that have the maximum ratings polarity between two genders and display top 10</span>
<span class="n">polar_movies</span> <span class="o">=</span> <span class="n">sqlCtx</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span>
    <span class="s1">&#39;select movie_title, F as female_rating, M as male_rating, (M-F) as diff from {0} order by abs(diff) desc limit 10&#39;</span><span class="o">.</span>
    <span class="n">format</span><span class="p">(</span><span class="n">pivot_avg_ratings</span><span class="o">.</span><span class="n">reg</span><span class="p">()))</span>

<span class="c1"># Display the movies</span>
<span class="n">pd_display</span><span class="p">(</span><span class="n">polar_movies</span><span class="o">.</span><span class="n">toPandas</span><span class="p">(),</span>
           <span class="s2">&quot;Top 10 movies that are rated differently by men and women.&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Conclusion">Conclusion<a class="anchor-link" href="#Conclusion">&#182;</a></h1><p>The key messages from this notebook are --</p>
<ol>
<li>Do not embark on the data lake journey and turn it into a swamp by diving in with the data</li>
<li>Good data lake begins with good governance; and good governance begins with good metadata</li>
<li>Ensure good data practices at inlet. Design a good data manifold to bring data in; shut down unregulated inlets for discouraging unauthorized transfers into the lake</li>
<li>Easily bring data from on-prem, cloud, local, internet, and enterprise sources with simple one-liners</li>
<li>Profile data immediately upon ingestion and assign a clear attribution to the data</li>
<li>Infer schemas automatically; also check data/schema integrity</li>
<li>Store raw data for provenance. But use massively parallel processing to shape and stage data for analytics</li>
<li>Enable easy physical, logical, or ephemeral integration with in-memory engine of Spark</li>
<li>Combine declarative, imperative, and functional style programming to cater to many skills and personas</li>
<li>Apply traditional star-models; apply analytical models as the challenge demands</li>
</ol>

</div>
</div>
</div>
        </div>
    </div>
    <footer>
        <div class="container row">
            <div class="pull-right"> <span class="copyright">Copyright © 2017. <a href="http://data-bloom.com">Data-Bloom</a></span></div>
        </div>
    </footer>

</html>
